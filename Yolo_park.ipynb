{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo_park.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LDWYg0DGvHqN",
        "colab": {}
      },
      "source": [
        "'''Detecting number of occupied parking spots. Code written keeping in mind the resources provided\n",
        "   under google colab \n",
        "'''\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LNRzAVNy-izy",
        "outputId": "d037a922-c9b6-49cf-d0e3-178239d04af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#mount your google drive to avoid losing data on colab when session expires \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXOJ-sOyiSqs",
        "colab_type": "code",
        "outputId": "db23b281-9861-433b-b1d0-50157c4dd889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")\n",
        "# Directory of images to run detection on\n",
        "ROOT_DIR = os.getcwd()\n",
        "print(ROOT_DIR)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11sRDwtbiPBT",
        "colab_type": "code",
        "outputId": "c9ef01e4-518e-48b7-a132-28f8ee5c7f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!pip install Cython\n",
        "!git clone https://github.com/waleedka/coco\n",
        "!pip install -U setuptools\n",
        "!pip install -U wheel\n",
        "\n",
        "os.getcwd()\n",
        "!mkdir results"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.7)\n",
            "fatal: destination path 'coco' already exists and is not an empty directory.\n",
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (41.0.1)\n",
            "Requirement already up-to-date: wheel in /usr/local/lib/python3.6/dist-packages (0.33.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hLVvkwHlsiRu",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import time\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2 \n",
        "from util import *\n",
        "from darknet import Darknet\n",
        "from preprocess import prep_image, inp_to_image, letterbox_image\n",
        "import pandas as pd\n",
        "import random \n",
        "import pickle as pkl\n",
        "import argparse\n",
        "\n",
        "\n",
        "def get_test_input(input_dim, CUDA):\n",
        "    img = cv2.imread(\"test_images/1.png\")\n",
        "    img = cv2.resize(img, (input_dim, input_dim)) \n",
        "    img_ =  img[:,:,::-1].transpose((2,0,1))\n",
        "    img_ = img_[np.newaxis,:,:,:]/255.0\n",
        "    img_ = torch.from_numpy(img_).float()\n",
        "    img_ = Variable(img_)\n",
        "    \n",
        "    if CUDA:\n",
        "        img_ = img_.cuda()\n",
        "    \n",
        "    return img_\n",
        "\n",
        "def prep_image(img, inp_dim):\n",
        "    \"\"\"\n",
        "    Prepare image for inputting to the neural network. \n",
        "    \n",
        "    Returns a Variable \n",
        "    \"\"\"\n",
        "\n",
        "    orig_im = img\n",
        "    dim = orig_im.shape[1], orig_im.shape[0]\n",
        "    img = (letterbox_image(orig_im, (inp_dim, inp_dim)))\n",
        "    img_ = img[:,:,::-1].transpose((2,0,1)).copy()\n",
        "    img_ = torch.from_numpy(img_).float().div(255.0).unsqueeze(0)\n",
        "    return img_, orig_im, dim\n",
        "\n",
        "def write(x, img, classes):\n",
        "    c1 = tuple(x[1:3].int())\n",
        "    c2 = tuple(x[3:5].int())\n",
        "    cls = int(x[-1])\n",
        "    label = \"{0}\".format(classes[cls])\n",
        "    color = (0,0,255)\n",
        "    cv2.rectangle(img, c1, c2,color, 1)\n",
        "    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
        "    c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
        "    cv2.rectangle(img, c1, c2,color, -1)\n",
        "    cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1);\n",
        "    return img\n",
        "\n",
        "def arg_parse():\n",
        "    \"\"\"\n",
        "    Parse arguements to the detect module\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    parser = argparse.ArgumentParser(description='YOLO v3')\n",
        "   \n",
        "    parser.add_argument(\"--dataset\", dest = \"dataset\", help = \"Dataset on which the network has been trained\", default = \"pascal\")\n",
        "    parser.add_argument(\"--confidence\", dest = \"confidence\", help = \"Object Confidence to filter predictions\", default = 0.5)\n",
        "    parser.add_argument(\"--nms_thresh\", dest = \"nms_thresh\", help = \"NMS Threshhold\", default = 0.4)\n",
        "    parser.add_argument(\"--cfg\", dest = 'cfgfile', help = \n",
        "                        \"Config file\",\n",
        "                        default = \"./cfg/yolov3.cfg\", type = str)\n",
        "    parser.add_argument(\"--weights\", dest = 'weightsfile', help = \n",
        "                        \"weightsfile\",\n",
        "                        default = \"yolov3.weights\", type = str)\n",
        "    parser.add_argument(\"--reso\", dest = 'reso', help = \n",
        "                        \"Input resolution of the network. Increase to increase accuracy. Decrease to increase speed\",\n",
        "                        default = \"704\", type = str)\n",
        "    \n",
        "    args = parser.parse_args(args=[])\n",
        "    \n",
        "    return args"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T-PFuE8SJkAY",
        "colab": {}
      },
      "source": [
        "# !wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3jsrBWnhXOQ",
        "colab_type": "code",
        "outputId": "0ed6cdfc-2113-41d5-9e94-55483e0411ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "MAX_PARKING = 100\n",
        "def get_freeslots(image):\n",
        "    batch_size = 15\n",
        "    args = arg_parse()\n",
        "    confidence = float(args.confidence)\n",
        "    nms_thesh = float(args.nms_thresh)\n",
        "    start = 0\n",
        "\n",
        "    CUDA = torch.cuda.is_available()\n",
        "\n",
        "    num_classes = 1\n",
        "\n",
        "    CUDA = torch.cuda.is_available()\n",
        "    \n",
        "    bbox_attrs = 5 + num_classes\n",
        "    \n",
        "    print(\"Loading network.....\")\n",
        "    model = Darknet(args.cfgfile)\n",
        "    model.load_weights(args.weightsfile)\n",
        "    print(\"Network successfully loaded\")\n",
        "\n",
        "    model.net_info[\"height\"] = args.reso\n",
        "    inp_dim = int(model.net_info[\"height\"])\n",
        "    #uncomment this if error occurs due to frame size\n",
        "#     assert inp_dim % 32 == 0 \n",
        "#     assert inp_dim > 32\n",
        "\n",
        "    if CUDA:\n",
        "        model.cuda()\n",
        "        \n",
        "    model(get_test_input(inp_dim, CUDA), CUDA)\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    frame = cv2.imread(image)\n",
        "    img, orig_im, dim = prep_image(frame, inp_dim)\n",
        "\n",
        "    im_dim = torch.FloatTensor(dim).repeat(1,2)                        \n",
        "\n",
        "\n",
        "    if CUDA:\n",
        "        im_dim = im_dim.cuda()\n",
        "        img = img.cuda()\n",
        "\n",
        "    with torch.no_grad():   \n",
        "        output = model(Variable(img), CUDA)\n",
        "    output = write_results(output, confidence, num_classes, nms = True, nms_conf = nms_thesh)\n",
        "    print(\"Total cars {}\".format(output.size(0)))\n",
        "\n",
        "    im_dim = im_dim.repeat(output.size(0), 1)\n",
        "    scaling_factor = torch.min(inp_dim/im_dim,1)[0].view(-1,1)\n",
        "\n",
        "    output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim[:,0].view(-1,1))/2\n",
        "    output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim[:,1].view(-1,1))/2\n",
        "\n",
        "    output[:,1:5] /= scaling_factor\n",
        "\n",
        "    for i in range(output.shape[0]):\n",
        "        output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim[i,0])\n",
        "        output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim[i,1])\n",
        "\n",
        "    classes = load_classes('data/coco.names')\n",
        "    colors = pkl.load(open(\"pallete\", \"rb\"))\n",
        "\n",
        "    list(map(lambda x: write(x, orig_im, classes), output))\n",
        "    empty = MAX_PARKING - output.size(0)\n",
        "    cv2.putText(orig_im, \"Parked: \" + str(output.size(0))+\" Empty: \" + str(empty), (80,50), cv2.FONT_ITALIC, 2, [0,0,0], 2, cv2.LINE_AA)\n",
        "    print(\"Total empty spots: \" + str(empty))\n",
        "    name = 'result.jpg'\n",
        "\n",
        "    name = os.path.join('./results', name)\n",
        "    cv2.imwrite(name, frame)\n",
        "    \n",
        "    \n",
        "get_freeslots('test_images/4.png')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading network.....\n",
            "Network successfully loaded\n",
            "Total cars 40\n",
            "Total empty spots: 60\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}